import streamlit as st
from openai import OpenAI
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Set up OpenAI API key and Assistant ID
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ASSISTANT_ID = os.getenv("OPENAI_ASSISTANT_ID")

# Initialize OpenAI client
client = OpenAI(api_key=OPENAI_API_KEY)

st.set_page_config(page_title="AIè‚²å„¿åŠ©æ‰‹", page_icon="ğŸ‘¶", layout="wide")

st.title("AIè‚²å„¿åŠ©æ‰‹")
st.subheader("è·å–å®æ—¶è‚²å„¿å»ºè®®ï¼Œæå‡æ‚¨çš„è‚²å„¿å†³ç­–æ•ˆç‡")

# Initialize chat history and thread
if "messages" not in st.session_state:
    st.session_state.messages = []
if "thread_id" not in st.session_state:
    st.session_state.thread_id = client.beta.threads.create().id

def generate_ai_response(prompt):
    try:
        # Add the user's message to the thread
        client.beta.threads.messages.create(
            thread_id=st.session_state.thread_id,
            role="user",
            content=prompt
        )

        # Run the assistant
        run = client.beta.threads.runs.create(
            thread_id=st.session_state.thread_id,
            assistant_id=ASSISTANT_ID
        )

        # Wait for the run to complete
        while run.status != "completed":
            run = client.beta.threads.runs.retrieve(
                thread_id=st.session_state.thread_id,
                run_id=run.id
            )

        # Retrieve the assistant's response
        messages = client.beta.threads.messages.list(thread_id=st.session_state.thread_id)
        return messages.data[0].content[0].text.value

    except Exception as e:
        return f"æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‡ºç°äº†é”™è¯¯: {str(e)}"

# Display chat messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Question type selection
question_type = st.selectbox(
    "é€‰æ‹©é—®é¢˜ç±»å‹",
    ("è‚²å„¿é—®é¢˜", "å¥åº·é—®é¢˜", "è¡Œä¸ºç®¡ç†"),
    key="question_type"
)

# Conditional input for parenting subcategory
parenting_subcategory = None
if question_type == "è‚²å„¿é—®é¢˜":
    parenting_subcategory = st.selectbox(
        "é€‰æ‹©å…·ä½“çš„è‚²å„¿é—®é¢˜ç±»å‹",
        ("ç¡çœ ", "é¥®é£Ÿ", "æ—©æ•™", "å…¶ä»–"),
        key="parenting_subcategory"
    )

# User input
user_input = st.chat_input("è¾“å…¥æ‚¨çš„è‚²å„¿é—®é¢˜ï¼Œè·å¾—å®æ—¶å»ºè®®")

if user_input:
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # Display user message
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # Generate AI response
    prompt = f"é—®é¢˜ç±»å‹: {question_type}\n"
    if parenting_subcategory:
        prompt += f"å…·ä½“é—®é¢˜: {parenting_subcategory}\n"
    prompt += f"é—®é¢˜: {user_input}\n\nè¯·æä¾›ç®€æ´å®ç”¨çš„è‚²å„¿å»ºè®®ã€‚"
    
    ai_response = generate_ai_response(prompt)
    
    # Add AI response to chat history
    st.session_state.messages.append({"role": "assistant", "content": ai_response})
    
    # Display AI response
    with st.chat_message("assistant"):
        st.markdown(ai_response)

# Clear chat button
if st.button("æ¸…ç©ºå¯¹è¯"):
    st.session_state.messages = []
    st.session_state.thread_id = client.beta.threads.create().id
    st.experimental_rerun()
